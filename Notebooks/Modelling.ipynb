{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assume that the claims count random variable N has a Poisson distribution with given years at risk v > 0 and expected frequency λ > 0. We aim at modeling the expected frequency λ > 0 such that it allows us to incorporate structural differences (heterogene-ity) between different insurance policies and risks; such structural differences are called systematic effects in the statistical literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "claimsdf = pd.read_csv('/home/julian/Cursos/Ironhack/Proyectos/ProyectoFinal/Claims-Frequency-Predictions/Notebooks/claimsdf_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClaimNb</th>\n",
       "      <th>Exposure</th>\n",
       "      <th>Area</th>\n",
       "      <th>BonusMalus</th>\n",
       "      <th>VehBrand</th>\n",
       "      <th>Density</th>\n",
       "      <th>Region</th>\n",
       "      <th>empirical_frequencies</th>\n",
       "      <th>VehGas_Regular</th>\n",
       "      <th>VehPower_</th>\n",
       "      <th>VehAge_</th>\n",
       "      <th>DrivAge_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>1217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.77</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>1217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.298701</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.190476</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ClaimNb  Exposure  Area  BonusMalus  VehBrand  Density  Region  \\\n",
       "0        1      0.10     4          50         9     1217     1.0   \n",
       "1        1      0.77     4          50         9     1217     1.0   \n",
       "2        1      0.75     2          50         9       54     5.0   \n",
       "3        1      0.09     2          50         9       76     7.0   \n",
       "4        1      0.84     2          50         9       76     7.0   \n",
       "\n",
       "   empirical_frequencies  VehGas_Regular  VehPower_  VehAge_  DrivAge_  \n",
       "0              10.000000               1          5        1         6  \n",
       "1               1.298701               1          5        1         6  \n",
       "2               1.333333               0          6        2         6  \n",
       "3              11.111111               0          7        1         5  \n",
       "4               1.190476               0          7        1         5  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claimsdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAKE OUT EMP FREQ, AGRUPAR REGIONES Y HACER HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "claimsdf.drop(columns=\"empirical_frequencies\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERALIZED LINEAR MODELS (Poisson case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The feature components interact in a multiplicative way in our Poisson GLM. One of the main tasks is to analyze whether this multiplicative interaction is appropriate.\n",
    "- A we have 4 categorical classes, then we need 3 indicators (dummy variables) to uniquely identify the parametrization of the (multiplicative) model including an intercept.\n",
    "- We consider 3 continuous feature components (Area, BonusMalus, log-Density), 1 binary feature component (VehGas) and 5 categorical feature components (VehPower, VehAge, DrivAge, VehBrand, Region)\n",
    "- If we consider the 5 continuous feature components VehAge, DrivAge, VehPower, Area and log_density as log-linear, VehGas as a binary component (0 or 1), and the 2 categorical components VehBrand and Region by dummy coding we get a feature space dimension q = 5 + 1 + 10 + 12 = 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TRAIN SAMPLE, TEST SAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Maximizing the log-likelihood for parameter β is equivalent to minimizing the deviance loss for β. In this spirit, the deviance loss plays the role of the canonical objective function that should be minimized. b is the scaled Poisson deviance loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVER DISPERSION CHECK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deviance statistics that accounts for potential over- or under-dispersion φ != 1. In the Poisson model this does not apply because by definition φ = 1 (variance equal to mean). We can determine this dispersion parameter empirically on our data by Pearson’s (distribution-free) dispersion estimate and and the deviance dispersion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The likelihood ratio test based on Posisson deviance can be applied recursively to a sequence of nested models. This leads to a step-wise reduction of model complexity, this is similar in spirit to the analysis of variance (ANOVA) in Listing 2.7, and it is often referred to as backward model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironcon",
   "language": "python",
   "name": "ironcon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
